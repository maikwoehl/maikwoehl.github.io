---
title: PipelinedIterator - a design pattern
author: Maik
layout: post
categories: journal
tags: [software, design, pattern]
---

Whenever you have an iteration process in an embedded systems context, you want to save time through iteration and you have to do some things before and after the iteration. The first idea will be a looping state machine or a really big chunk of code that will sequentially execute before and after the iteration step occurs. Both ways have some downsides: On the one hand you can't afford to spend the time on stepping through a looping state machine and on the other hand you don't want to have big chunks of code. For that problem here is a solution: Embedding an iterator structure into an iterator-powered pipeline.

But first we discuss some related work to show that the concept is not new, but different to others.

## Related work
Zhu describes in his work [1] a pipeline software architecture for signal processing. It is the standard way of converting an analog signal to digital, process it and convert an response signal from digital to analog. He says that a parallel processing of information through a pipeline will be faster than a sequential state-dependent processing. That can be translated to software architecture and there the same effects appear. For a pipeline architecture substantially more memory than for a state-based architecture is needed, because you must store information between phases in memory and transport it through the pipeline.

The Rust crate iterpipes [2] allows to connect multiple iterators with different actions together. That is something like this pattern, because every stage or phase is pushed forward with every next()-call. By chaining the iterpipes together it is possible to get a similiar behaviour like this pattern describes.

## Concept
The *PipelinedIterator* allows to execute queued instructions on an element that changes on every iteration. A processing cycle consists of the four phases fetch, decode, execute and write. Whatever program is executing in the execution phase controls the iteration speed. 

The fetch phase is responsible for checking the limits of the list object and fetching the next element or signaling an upcoming halt.

The decode phase prepares the data structures used by the execution phase. It also generates control signals for the programs in execution phase. In this phase any other input signal can be processed and translated into a set of control and data signals for the execution phase. In other words the injection of additional informations and conditions into the iteration process is possible.

The execution phase consists of all data processing related tasks. All informations that are generated by a given element and input signals will be handed over to the write phase.

The write phase than generates the output signals of the outer object. 

Let's define some constraints to get a stable model:

 * Every phase must implement an asynchronous reset to switch to initial or default values in case of an iteration restart signal. 
 * It is a matter of implementation in the fetch phase whether the pipeline can traverse the objects forwards or backwards. A traversal from both sides in a switching manner is possible, if the execution phase don't expect a specific order of iteration.
 * Control and data signals inside the phases are read-only or write-only.
 * All phases must be aware of an outer halt signal as every outer event can lead to an execution or iteration halt.
 * In a case of a halt the write phase must be able to finish the write operation or must store the information beyond a possible reset to prevent data loss.
 * A halt signal should not flush the phases state memory. 
 * The execution phase should have the possibility to stall the pipeline as well. Any program could need more time for calculations so the pipeline must be able to wait if needed. The iteration then must be delayable.

As this definition enforces the control and data signals to be read or write only inside the phases, a buffer between the phases must be implemented. If the outer process is reading informations from the pipeline, they must be copied to prevent any effect on the pipeline process. 

It seems an interface for start and halt input signals, any input or output data and done and stall output signals should be sufficient. For further study a research implementation is presented below. In a production environment the programmer can be forced to include additional conditions (and heuristics) to meet system constraints (time, sensors, etc...)

# Concretization
The phase-buffer can programmatically written as a `struct`, one struct for the data paths between phases and one struct for the control paths between phases. The original structures are initialized by the phases and a copy is passed to the buffer. To prevent a data change on accident an immutable reference to the copy is passed to the next phase. The outer structure can access the buffer contents through immutable references or copies, if needed. 

Due to the use case for embedded software the execution phase may need more than one cycle, so a *pipeline stall* signal must be provided. A ready flag can be emitted to provide an information about the running calculations. Therefore the next iteration is only processed when the execution phase signals a ready state. 

A stop signal flushes the buffers except the last one. The write process must be completed to prevent loss of already calculated results. The write phase is defined as the official data exit because the data flow path inside the pipeline ends there. So the write phase needs a done flag.

# Proof-of-concept

Let's start with a data structure:

```rust
struct IterData<T> {
    data: T,
}
```

The data is generic over `T` because the concrete type is not known at this point. As we can implement traits in Rust we can introduce a *Pipeline* trait:

```rust
trait Pipeline {
    fn clk(&self) -> bool;
    fn rst(&self) -> bool;
    fn stall(&self) -> bool;
    fn halt(&self) -> bool;
}
```

Now we are able to create our phase structures with a pipeline implementation. For this we need an example situation. Let's introduce a testsystem: We have a list of test identifier that we can iterate over. For every test we want to give it to a program that handles the test execution. The test program has the following interface:

```rust
fn test(
    test_control: &mut TestControl,
    input:  &mut DevicesInput,
    next_key: &mut bool,
    halt: &mut bool); 
``` 

The Rust-Ownership model requires the execution phase to be the owner of the variables passed to this function. Now we know the required informations and can design our phases.

## Fetch

The fetch phase holds an iterator and reads from the list of test identifier. When the list exhausted a `done` signal must be send.

```rust
struct Fetch {
    test_ids: Iter<Vec<String>>,
    index: u32,
    done: bool,
}

impl Fetch {
    fn new(id_iter: Iter<Vec<String>>) -> Self {
        Self {
            test_ids: id_iter,
            index: 0, 
            done: false,
        }
    }
    fn run(&mut self) -> Option<String> {
        match self.test_ids.next() {
            Some(key) => Some(key),
            None => {
                self.done = true;
                None
            },
        }
    }
    fn is_done(&self) -> bool {
        self.done
    }
}
```

## Decode

## Execution

## Write

## Conclusion 
<!-- TODO: write about phase implementations -->


# References
 1. M. Zhu, W. Liu, Z. Fang and W. Hu, "Design of Pipeline Structure to Improve Data Acquisition Rate," 2008 International Workshop on Education Technology and Training & 2008 International Workshop on Geoscience and Remote Sensing, Shanghai, 2008, pp. 783-786, doi: 10.1109/ETTandGRS.2008.318. [https://ieeexplore.ieee.org/document/5070268](https://ieeexplore.ieee.org/document/5070268)
 2. [https://docs.rs/iterpipes/0.2.0/iterpipes/](https://docs.rs/iterpipes/0.2.0/iterpipes/)
